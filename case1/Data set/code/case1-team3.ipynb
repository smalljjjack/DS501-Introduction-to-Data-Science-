{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1 : Data Science in Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book [Mining the Social Web](http://cdn.oreillystatic.com/oreilly/booksamplers/9781449367619_sampler.pdf) \n",
    "* The codes for [Chapter 1](http://bit.ly/1qCtMrr) and [Chapter 9](http://bit.ly/1u7eP33)\n",
    "* [TED Talks](https://www.ted.com/talks) for examples of 10 minutes talks.\n",
    "\n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in Jupyter Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: pick a data science problem that you plan to solve using Twitter Data\n",
    "* The problem should be important and interesting, which has a potential impact in some area.\n",
    "* The problem should be solvable using twitter data and data science solutions.\n",
    "\n",
    "Please briefly describe in the following cell: what problem are you trying to solve? why this problem is important and interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe superbowl is a huge US sports event. This year New England Patriots play against the Atlanta Falcons \\nin Houston Texas. Twitter data has been collected from the New England, Atlanta and Houston areas.  \\nThis data can be used to identify potential advertising customers. New England , Houston and Atlanta areas represent\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The superbowl is a huge US sports event. This year New England Patriots play against the Atlanta Falcons \n",
    "in Houston Texas. Twitter data has been collected from the New England, Atlanta and Houston areas.  \n",
    "This data can be used to identify potential advertising customers. New England , Houston and Atlanta areas represent\n",
    "different marketing areas. Which area is the better investment for superbowl advertising?\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection: Download Twitter Data using API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In order to solve the above problem, you need to collect some twitter data. You could select a topic that is relevant to your problem, and use Twitter API to download the relevant tweets. It is recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Twitter Query: query=#Superbowl OR superbowl OR party resultType=mixed ...\n",
      "     subquery: query=#Superbowl resultType=mixed ...\n",
      "     30 tweets subquery=#Superbowl resultType=mixed\n",
      "     subquery: query=superbowl resultType=mixed ...\n",
      "     164 tweets subquery=superbowl resultType=mixed\n",
      "     subquery: query=party resultType=mixed ...\n",
      "     19 tweets subquery=party resultType=mixed\n",
      "213 tweets query=#Superbowl OR superbowl OR party resultType=mixed\n",
      "Executing Twitter Query: query=#Superbowl Boston OR superbowl Boston OR party Boston resultType=mixed ...\n",
      "     subquery: query=#Superbowl Boston resultType=mixed ...\n",
      "     30 tweets subquery=#Superbowl Boston resultType=mixed\n",
      "     subquery: query=superbowl Boston resultType=mixed ...\n",
      "     30 tweets subquery=superbowl Boston resultType=mixed\n",
      "     subquery: query=party Boston resultType=mixed ...\n",
      "     30 tweets subquery=party Boston resultType=mixed\n",
      "90 tweets query=#Superbowl Boston OR superbowl Boston OR party Boston resultType=mixed\n",
      "Executing Twitter Query: query=#Superbowl Worcester OR superbowl Worcester OR party Worcester resultType=mixed ...\n",
      "     subquery: query=#Superbowl Worcester resultType=mixed ...\n",
      "     14 tweets subquery=#Superbowl Worcester resultType=mixed\n",
      "     subquery: query=superbowl Worcester resultType=mixed ...\n",
      "     18 tweets subquery=superbowl Worcester resultType=mixed\n",
      "     subquery: query=party Worcester resultType=mixed ...\n",
      "     25 tweets subquery=party Worcester resultType=mixed\n",
      "57 tweets query=#Superbowl Worcester OR superbowl Worcester OR party Worcester resultType=mixed\n",
      "Executing Twitter Query: query=#Superbowl Providence OR superbowl Providence OR party Providence resultType=mixed ...\n",
      "     subquery: query=#Superbowl Providence resultType=mixed ...\n",
      "     17 tweets subquery=#Superbowl Providence resultType=mixed\n",
      "     subquery: query=superbowl Providence resultType=mixed ...\n",
      "     17 tweets subquery=superbowl Providence resultType=mixed\n",
      "     subquery: query=party Providence resultType=mixed ...\n",
      "     30 tweets subquery=party Providence resultType=mixed\n",
      "64 tweets query=#Superbowl Providence OR superbowl Providence OR party Providence resultType=mixed\n",
      "Executing Twitter Query: query=#Superbowl Nashua OR superbowl Nashua OR party Nashua resultType=mixed ...\n",
      "     subquery: query=#Superbowl Nashua resultType=mixed ...\n",
      "     0 tweets subquery=#Superbowl Nashua resultType=mixed\n",
      "     subquery: query=superbowl Nashua resultType=mixed ...\n",
      "     1 tweets subquery=superbowl Nashua resultType=mixed\n",
      "     subquery: query=party Nashua resultType=mixed ...\n",
      "     6 tweets subquery=party Nashua resultType=mixed\n",
      "7 tweets query=#Superbowl Nashua OR superbowl Nashua OR party Nashua resultType=mixed\n",
      "Executing Twitter Query: query=#Superbowl Atlanta OR superbowl Atlanta OR party Atlanta resultType=mixed ...\n",
      "     subquery: query=#Superbowl Atlanta resultType=mixed ...\n",
      "     30 tweets subquery=#Superbowl Atlanta resultType=mixed\n",
      "     subquery: query=superbowl Atlanta resultType=mixed ...\n",
      "     30 tweets subquery=superbowl Atlanta resultType=mixed\n",
      "     subquery: query=party Atlanta resultType=mixed ...\n",
      "     30 tweets subquery=party Atlanta resultType=mixed\n",
      "90 tweets query=#Superbowl Atlanta OR superbowl Atlanta OR party Atlanta resultType=mixed\n",
      "Executing Twitter Query: query=#Superbowl Macon OR superbowl Macon OR party Macon resultType=mixed ...\n",
      "     subquery: query=#Superbowl Macon resultType=mixed ...\n",
      "     10 tweets subquery=#Superbowl Macon resultType=mixed\n",
      "     subquery: query=superbowl Macon resultType=mixed ...\n",
      "     16 tweets subquery=superbowl Macon resultType=mixed\n",
      "     subquery: query=party Macon resultType=mixed ...\n",
      "     16 tweets subquery=party Macon resultType=mixed\n",
      "42 tweets query=#Superbowl Macon OR superbowl Macon OR party Macon resultType=mixed\n",
      "Executing Twitter Query: query=#Superbowl Houston OR superbowl Houston OR party Houston resultType=mixed ...\n",
      "     subquery: query=#Superbowl Houston resultType=mixed ...\n",
      "     30 tweets subquery=#Superbowl Houston resultType=mixed\n",
      "     subquery: query=superbowl Houston resultType=mixed ...\n",
      "     30 tweets subquery=superbowl Houston resultType=mixed\n",
      "     subquery: query=party Houston resultType=mixed ...\n",
      "     11 tweets subquery=party Houston resultType=mixed\n",
      "71 tweets query=#Superbowl Houston OR superbowl Houston OR party Houston resultType=mixed\n",
      "634 total tweets 8 queries\n"
     ]
    }
   ],
   "source": [
    "import twitter\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "CONSUMER_KEY = '4bVYOyoJP3Jwcf5SQflhV4qcT'\n",
    "CONSUMER_SECRET = 'l45TjHGHN2G5vA0sv5q9xhlM6F9IyQwYIgDnm9qSLD3vjEP1aG'\n",
    "OAUTH_TOKEN = '825413411089571841-YcKtJ9LEXWMjSdgFVT5eueuJpdGygB1'\n",
    "OAUTH_TOKEN_SECRET = 'Qx9Q8aIRX6FgloBl5D1dI8ZoZU3x95nNH9NrjS6aULg7A'\n",
    "\n",
    "MAX_ALLOWED_TWEETS = 2000\n",
    "# search has a 7-day limit. so they're only ever in the last week.\n",
    "MAX_DAYS_PER_QUERY = 7\n",
    "WORLD_WOEID = 1\n",
    "USA_WOEID = 23424977\n",
    "MA_WOEID = 2347580 # No Trends Found\n",
    "WORCESTER_MA_WOEID = 2523945 # No Trends Found\n",
    "WPI_LAT = 42.2749\n",
    "WPI_LON = -71.8092\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "def twitter_oauth_login():\n",
    "    # Go to http://twitter.com/apps/new to create an app and get values\n",
    "    # for these credentials that you'll need to provide in place of these\n",
    "    # empty string values that are defined as placeholders.\n",
    "    # See https://dev.twitter.com/docs/auth/oauth for more information\n",
    "    # on Twitter's OAuth implementation.\n",
    "    # studentllpage1 info\n",
    "\n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n",
    "# ----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "# ----------------------------------------------\n",
    "# query_twitter return array of statuses\n",
    "# twitterAPI  - required logged in twitter handle\n",
    "# query - required twitter Query to execute  'OR' queries are split into individual queries whose results are combined.\n",
    "# resultType - optional type of tweets to get, 'popular' (most popular), 'recent' (most recent), or 'mixed' (popular or most recent) (default: mixed)\n",
    "# lat, lon, radius  - optional latitude, longitude, and radius (in miles) in which to confine search geographically (default: none)\n",
    "# untilDate - optional date to query tweets until (default: none)\n",
    "# return array of statuses extracted from query results\n",
    "#\n",
    "def query_twitter(twitterAPI, query,\n",
    "                  resultType = 'mixed',\n",
    "                  lat = None, lon = None, radius = None,\n",
    "                  untilDate = None):\n",
    "    subqueries = query.split(' OR ')\n",
    "    queryFilters = 'resultType={1}'.format(query, resultType)\n",
    "    geocodeFilter = None\n",
    "    if lat and lon and radius:\n",
    "        geocodeFilter = '{0},{1},{2}mi'.format(lat, lon, radius)\n",
    "        queryFilters = '{0} geocode={1}'.format(queryFilters, geocodeFilter)\n",
    "    if untilDate:\n",
    "        queryFilters = '{0} until={1}'.format(queryFilters, untilDate)\n",
    "\n",
    "    results = []\n",
    "    print('Executing Twitter Query: query={0} {1} ...'.format(query, queryFilters))\n",
    "    for subquery in subqueries:\n",
    "        queryResults = None\n",
    "        newQuery = subquery\n",
    "        print('     subquery: query={0} {1} ...'.format(subquery, queryFilters))\n",
    "        if geocodeFilter:\n",
    "            if untilDate:\n",
    "                queryResults = twitterAPI.search.tweets(q=newQuery, result_type=resultType,\n",
    "                                                        geocode=geocodeFilter, until=untilDate)\n",
    "            else:\n",
    "                queryResults = twitterAPI.search.tweets(q=newQuery, result_type=resultType, geocode=geocodeFilter)\n",
    "        else:\n",
    "            if untilDate:\n",
    "                queryResults = twitterAPI.search.tweets(q=newQuery, result_type=resultType, until=untilDate)\n",
    "            else:\n",
    "                queryResults = twitterAPI.search.tweets(q=newQuery, result_type=resultType)\n",
    "        continueCollectResults = True\n",
    "        lastCollectedResults = len(results)\n",
    "        totalCollectedResults = 0\n",
    "        while continueCollectResults:\n",
    "            next_results = None\n",
    "            try:\n",
    "                next_results = queryResults['search_metadata']['next_results']\n",
    "            except:  # No more results when next_results doesn't exist\n",
    "                continueCollectResults = False\n",
    "            statuses = queryResults['statuses']\n",
    "            totalCollectedResults += len(statuses)\n",
    "\n",
    "            results += statuses\n",
    "            if not (continueCollectResults):\n",
    "                print('     {0} tweets subquery={1} {2}'.format(len(results) - lastCollectedResults, newQuery, queryFilters))\n",
    "                lastCollectedResults = len(results)\n",
    "                break\n",
    "            # Create a dictionary from next_results, which has the following form:\n",
    "            # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "            kwargs = dict([kv.split('=') for kv in next_results[1:].split(\"&\")])\n",
    "            queryResults = twitterAPI.search.tweets(**kwargs)\n",
    "    print('{0} tweets query={1} {2}'.format(len(results), query, queryFilters))\n",
    "    return results\n",
    "\n",
    "def query_to_filename(query):\n",
    "    return query.replace('#','').replace('@','').replace(':','_').replace(' ','_') + '.json'\n",
    "#\n",
    "# write 'data' to 'filename' as JSON\n",
    "#\n",
    "def write_to_file(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    f.closed\n",
    "\n",
    "#\n",
    "# read 'filename' as JSON into returned data\n",
    "#\n",
    "def read_from_file(filename):\n",
    "    result = None\n",
    "    with open(filename, 'r') as f:\n",
    "        result = json.load( f)\n",
    "    f.closed\n",
    "    return result\n",
    "#------------------------------------------------------------\n",
    "\n",
    "#QUERIES:\n",
    "\n",
    "queries = [ '#Superbowl OR superbowl OR party',\n",
    "            '#Superbowl Boston OR superbowl Boston OR party Boston',\n",
    "            '#Superbowl Worcester OR superbowl Worcester OR party Worcester',\n",
    "            '#Superbowl Providence OR superbowl Providence OR party Providence',\n",
    "            '#Superbowl Nashua OR superbowl Nashua OR party Nashua',\n",
    "            '#Superbowl Atlanta OR superbowl Atlanta OR party Atlanta',\n",
    "            '#Superbowl Macon OR superbowl Macon OR party Macon',\n",
    "            '#Superbowl Houston OR superbowl Houston OR party Houston'\n",
    "            ]\n",
    "twitterapi= twitter_oauth_login()\n",
    "today = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "totalTweets = 0\n",
    "for query in queries:\n",
    "    filename = today + '.' + query_to_filename(query)\n",
    "    twitter_statuses = query_twitter(twitterapi,query,'mixed')\n",
    "    #twitter_statuses = query_twitter_dateranges(twitterapi, '2011-01-31 2011-02-06  2012-01-29', query, 'mixed')\n",
    "    write_to_file(twitter_statuses, filename)\n",
    "    totalTweets += len(twitter_statuses)\n",
    "print('{0} total tweets {1} queries'.format(totalTweets, len(queries)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report  statistics about the tweets you collected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The total number of tweets collected:  634"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration: Exploring the Tweets and Tweet Entities\n",
    "\n",
    "**(1) Word Count:** \n",
    "* Load the tweets you collected in the local file (txt or json)\n",
    "* compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 most-frequent words with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (2) Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 most-retweeted tweets in your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot the top 10 most-frequent hashtags and top 10 most-mentioned users in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of the number of user mentions in the list using the following bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins=[0, 10, 20, 30, 40, 50, 100]\n",
    "\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " ** (4) Getting \"All\" friends and \"All\" followers of a popular user in the tweets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose a popular twitter user who has many followers in your collection of tweets.\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Solution: implement a data science solution to the problem you are trying to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly describe the idea of your solution to the problem in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The idea of this solution is to collect twitter data, through the python twitter API, related to the superbowl \n",
    "and superbowl parties in parts of New England, around the Atlanta Georgia area, and in Houston Texas. \n",
    "The collected tweet counts \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write codes to implement the solution in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results: summarize and visualize the results discovered from the analysis\n",
    "\n",
    "Please use figures, tables, or videos to communicate the results with the audience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this Jupyter notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"jupyter notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "* **PPT Slides**: please prepare PPT slides (for 10 minutes' talk) to present about the case study . Each team present their case studies in class for 10 minutes.\n",
    "\n",
    "Please compress all the files in a zipped file.\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "\n",
    "        Please submit through Canvas, in the Assignment \"Case Study 1\".\n",
    "        \n",
    "** Note: Each team only needs to submit one submission in Canvas **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Peer-Review Grading Template:\n",
    "\n",
    "** Total Points: (100 points) ** Please don't worry about the absolute scores, we will rescale the final grading according to the performance of all teams in the class.\n",
    "\n",
    "Please add an \"**X**\" mark in front of your rating: \n",
    "\n",
    "For example:\n",
    "\n",
    "*2: bad*\n",
    "          \n",
    "**X** *3: good*\n",
    "    \n",
    "*4: perfect*\n",
    "\n",
    "\n",
    "    ---------------------------------\n",
    "    The Problem: \n",
    "    ---------------------------------\n",
    "    \n",
    "    1. (5 points) how well did the team describe the problem they are trying to solve using twitter data? \n",
    "       0: not clear\n",
    "       1: I can barely understand the problem\n",
    "       2: okay, can be improved\n",
    "       3: good, but can be improved\n",
    "       4: very good\n",
    "       5: crystal clear\n",
    "    \n",
    "    2. (10 points) do you think the problem is important or has a potential impact?\n",
    "        0: not important at all\n",
    "        2: not sure if it is important\n",
    "        4: seems important, but not clear\n",
    "        6: interesting problem\n",
    "        8: an important problem, which I want to know the answer myself\n",
    "       10: very important, I would be happy invest money on a project like this.\n",
    "    \n",
    "    ----------------------------------\n",
    "    Data Collection:\n",
    "    ----------------------------------\n",
    "    \n",
    "    3. (10 points) Do you think the data collected are relevant and sufficient for solving the above problem? \n",
    "       0: not clear\n",
    "       2: I can barely understand what data they are trying to collect\n",
    "       4: I can barely understand why the data is relevant to the problem\n",
    "       6: the data are relevant to the problem, but better data can be collected\n",
    "       8: the data collected are relevant and at a proper scale (> 300 tweets)\n",
    "      10: the data are properly collected and they are sufficient\n",
    "\n",
    "    -----------------------------------\n",
    "    Data Exploration:\n",
    "    -----------------------------------\n",
    "    4. How well did the team solve the following task:\n",
    "    (1) Word Count (5 points):\n",
    "       0: missing answer\n",
    "       1: okay, but with major problems\n",
    "       3: good, but with minor problems\n",
    "       5: perfect\n",
    "    \n",
    "    (2) Find the most popular tweets in your collection of tweets: (5 points)\n",
    "       0: missing answer\n",
    "       1: okay, but with major problems\n",
    "       3: good, but with minor problems\n",
    "       5: perfect\n",
    "    \n",
    "    (3) Find popular twitter entities  (5 points)\n",
    "       0: missing answer\n",
    "       1: okay, but with major problems\n",
    "       3: good, but with minor problems\n",
    "       5: perfect\n",
    "\n",
    "    (4) Find user's followers and friends (5 points)\n",
    "       0: missing answer\n",
    "       1: okay, but with major problems\n",
    "       3: good, but with minor problems\n",
    "       5: perfect\n",
    "\n",
    "    -----------------------------------\n",
    "    The Solution\n",
    "    -----------------------------------\n",
    "    5.  how well did the team describe the solution they used to solve the problem? \n",
    "       0: not clear\n",
    "       2: I can barely understand\n",
    "       4: okay, can be improved\n",
    "       6: good, but can be improved\n",
    "       8: very good\n",
    "       10: crystal clear\n",
    "       \n",
    "    6. how well is the solution in solving the problem? \n",
    "       0: not relevant\n",
    "       1: barely relevant to the problem\n",
    "       2: okay solution, but there is an easier solution.\n",
    "       3: good, but can be improved\n",
    "       4: very good, but solution is simple/old\n",
    "       5: innovative and technically sound\n",
    "       \n",
    "    7. how well did the team implement the solution in python? \n",
    "       0: the code is not relevant to the solution proposed\n",
    "       2: the code is barely understandable, but not relevant\n",
    "       4: okay, the code is clear but incorrect\n",
    "       6: good, the code is correct, but with major errors\n",
    "       8: very good, the code is correct, but with minor errors\n",
    "      10: perfect \n",
    "   \n",
    "    -----------------------------------\n",
    "    The Results\n",
    "    -----------------------------------\n",
    "     8.  How well did the team present the results they found in the data? \n",
    "       0: not clear\n",
    "       2: I can barely understand\n",
    "       4: okay, can be improved\n",
    "       6: good, but can be improved\n",
    "       8: very good\n",
    "      10: crystal clear\n",
    "       \n",
    "     9.  How do you think the results they found in the data? \n",
    "       0: not clear\n",
    "       1: likely to be wrong\n",
    "       2: okay, maybe wrong\n",
    "       3: good, but can be improved\n",
    "       4: make sense, but not interesting\n",
    "       5: make sense and very interesting\n",
    "     \n",
    "    -----------------------------------\n",
    "    The Presentation\n",
    "    -----------------------------------\n",
    "    10. How all the different parts (data, problem, solution, result) fit together as a coherent story?  \n",
    "       0: they are irrelevant\n",
    "       1: I can barely understand how they are related to each other\n",
    "       2: okay, the problem is good, but the solution doesn't match well, or the problem is not solvable.\n",
    "       3: good, but the results don't make much sense in the context\n",
    "       4: very good fit, but not exciting (the storyline can be improved/polished)\n",
    "       5: a perfect story\n",
    "      \n",
    "    11. Did the presenter make good use of the 10 minutes for presentation?  \n",
    "       0: the team didn't present\n",
    "       1: bad, barely finished a small part of the talk\n",
    "       2: okay, barely finished most parts of the talk.\n",
    "       3: good, finished all parts of the talk, but some part is rushed\n",
    "       4: very good, but the allocation of time on different parts can be improved.\n",
    "       5: perfect timing and good use of time      \n",
    "\n",
    "    12. How well do you think of the presentation (overall quality)?  \n",
    "       0: the team didn't present\n",
    "       1: bad\n",
    "       2: okay\n",
    "       3: good\n",
    "       4: very good\n",
    "       5: perfect\n",
    "\n",
    "\n",
    "    -----------------------------------\n",
    "    Overall: \n",
    "    -----------------------------------\n",
    "    13. How many points out of the 100 do you give to this project in total?  Please don't worry about the absolute scores, we will rescale the final grading according to the performance of all teams in the class.\n",
    "    Total score:\n",
    "    \n",
    "    14. What are the strengths of this project? Briefly, list up to 3 strengths.\n",
    "       1: \n",
    "       2:\n",
    "       3:\n",
    "    \n",
    "    15. What are the weaknesses of this project? Briefly, list up to 3 weaknesses.\n",
    "       1:\n",
    "       2:\n",
    "       3:\n",
    "    \n",
    "    16. Detailed comments and suggestions. What suggestions do you have for this project to improve its quality further.\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ---------------------------------\n",
    "    Your Vote: \n",
    "    ---------------------------------\n",
    "    1. [Overall Quality] Between the two submissions that you are reviewing, which team would you vote for a better score?  \n",
    "       -1: I vote the other team is better than this team\n",
    "        0: the same\n",
    "        1: I vote this team is better than the other team \n",
    "        \n",
    "    2. [Presentation] Among all the teams in the presentation, which team do you think deserves the best presentation award for this case study?  \n",
    "        1: Team 1\n",
    "        2: Team 2\n",
    "        3: Team 3\n",
    "        4: Team 4\n",
    "        5: Team 5\n",
    "        6: Team 6\n",
    "        7: Team 7\n",
    "        8: Team 8\n",
    "        9: Team 9\n",
    "       10: Team 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
